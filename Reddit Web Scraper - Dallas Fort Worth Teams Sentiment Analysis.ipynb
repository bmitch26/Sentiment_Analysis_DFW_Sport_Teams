{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "120c4ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data from /r/TexasRangers\n",
      "Collecting data from /r/cowboys\n",
      "Collecting data from /r/Mavericks\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Brett Mitchell\n",
    "\n",
    "2/8/2024 was a big day for Dallas-Fort Worth sports fans - On this day, the Cowboys hired a new defensive coordinator, the\n",
    "Rangers resigned one their all-star players, and the Mavericks traded for two key players right before the NBA trade \n",
    "deadline. As a result, I was curious to find out fan sentiment for all three teams. As a result, I scraped the most recent\n",
    "Reddit data from all three teams and compared the results to see which set of fans are the most generally positive and\n",
    "negative about their team.\n",
    "\n",
    "I predict that each team will show a mostly positive sentiment about their team, with the Rangers showing the most. The\n",
    "Rangers are coming off of their first World Series win and after months of waiting, finally re-signed arguably their best\n",
    "playoff contributor. As for the Cowboys, I predict that their fans will show the most negative sentiment towards their team,\n",
    "as they suffered a huge playoff loss and the new defensive coordinator hire may be a bit controversial.\n",
    "\n",
    "As for the VADER model, I predict that it will show a very high level of accuracy in predicting sentiment of the web scraped\n",
    "Reddit comments due to its high level of previous training data and its well-known regard for sentiment analysis.\n",
    "'''\n",
    "\n",
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "# Reddit client credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"client_id\",\n",
    "    client_secret=\"client_secret\",\n",
    "    user_agent=\"brtm23_sentiment_analysis\"\n",
    ")\n",
    "\n",
    "def sa_scraper(subreddits):\n",
    "    subreddit_dfs = {}  # holds subreddit DataFrames\n",
    "    \n",
    "    for subreddit_name in subreddits:\n",
    "        print(f\"Collecting data from /r/{subreddit_name}\")\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "        comments_data = []  # collects comments\n",
    "        \n",
    "        for submission in subreddit.new(limit=330):\n",
    "            submission.comments.replace_more(limit=0)  # Load comments\n",
    "            for comment in submission.comments.list():\n",
    "                # Collect comment data\n",
    "                comments_data.append({'comment_body': comment.body})\n",
    "        \n",
    "        # Create DataFrame for the current subreddit\n",
    "        subreddit_dfs[subreddit_name] = pd.DataFrame(comments_data)\n",
    "    \n",
    "    return subreddit_dfs\n",
    "\n",
    "# Subreddits of interest with respective limits\n",
    "subreddits = ['TexasRangers','cowboys','Mavericks']\n",
    "\n",
    "# Collecting data\n",
    "subreddit_dataframes = sa_scraper(subreddits)\n",
    "\n",
    "# Accessing each DataFrame\n",
    "rangers_comments_df = subreddit_dataframes['TexasRangers']\n",
    "cowboys_comments_df = subreddit_dataframes['cowboys']\n",
    "mavericks_comments_df = subreddit_dataframes['Mavericks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62da7bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        comment_body\n",
      "0                         14 1/2 minutes of pure sex\n",
      "1  14 minutes…I’m not going to wa- OH I REMEMBER ...\n",
      "2                  Those Garcia HRs hit harder today\n",
      "3  Crazy he is just 35. Older yes but to think he...\n",
      "4  Man, it was fun watching this guy just throw c...\n",
      "(9245, 1)\n",
      "(29818, 1)\n",
      "(21875, 1)\n"
     ]
    }
   ],
   "source": [
    "print(rangers_comments_df.head())\n",
    "\n",
    "print(rangers_comments_df.shape)\n",
    "print(cowboys_comments_df.shape)\n",
    "print(mavericks_comments_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09dc32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rangers_comments_df.to_csv(\"rangers_comments_sentiment_analysis\", index=False)\n",
    "cowboys_comments_df.to_csv(\"cowboys_comments_sentiment_analysis\", index=False)\n",
    "mavericks_comments_df.to_csv(\"mavericks_comments_sentiment_analysis\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
